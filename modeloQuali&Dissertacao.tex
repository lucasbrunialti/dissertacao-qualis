\documentclass[normaltoc, espacoumemeio, pnumromarab,ruledheader]{abnt}		


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage[brazil]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amstext}
\usepackage{amssymb}
\usepackage{theorem}
\usepackage{fancyhdr}
\usepackage{epsf}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
% \usepackage{subfigure}
\usepackage[linesnumbered,boxed,vlined,portuguese]{algorithm2e}
%\usepackage[Conny]{fncychap}
%\usepackage{hyperref}
%\usepackage[all]{hypcap} 
%\hypersetup{urlcolor=cyan}
%\usepackage{acronym} 

\usepackage{rotating} % UTILIZADO PELO AMBIENTE SIDEWAYTABLE PARA TABELAS GIRADAS DE 90o
\usepackage{booktabs} % ALTERA O LAYOUT DE TABELAS
\usepackage{longtable} % CRIA TABELAS EM MAIS DE UMA PÁGINA
\usepackage{float} % MELHORA O POSICIONAMENTO DE OBJETOS FLOAT COMO FIGURAS E TABELAS
\usepackage[format=hang,font=it,justification=centerlast,labelfont=bf,labelsep=endash]{caption} % FORMATA A LEGENDA DE TABELAS E FIGURAS

\usepackage{color}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%\newif\ifpdf
%\ifx\pdfoutput\undefined
%	\pdffalse
%\else
%	\pdftrue
%\fi

%\ifpdf
%\pdfoutput=1
\usepackage{graphicx}
\usepackage[output=pdf]{logo-each}
%\else
% Enables the usage of graphics in .jpg format, rather than .eps
% (Encapsulated PostScript).
% Furthermore, is also required by package logo-each below.
%\usepackage{graphicx}
%\usepackage{logo-each}	% EACH-USP logo.
%\fi

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Additional ABNTex definitions.
%\usepackage[disable=copyright,disable=biblabel]{ach2017}




\newtheorem{theorem}{Teorema}
\newtheorem{acknowledgement}{Acknowledgement}
\newtheorem{axiom}{Axioma}
\newtheorem{case}{Caso}
\newtheorem{Propriedade}{Propriedade}
\newtheorem{claim}{Claim}
\newtheorem{conclusion}{Conclus\~ao}
\newtheorem{condition}{Condi\c{c}\~ao}
\newtheorem{conjecture}{Conjectura}
\newtheorem{corollary}{Corol\'ario}
\newtheorem{criterion}{Criterio}
\newtheorem{definition}{Defini\c{c}\~ao}
\newtheorem{example}{Exemplo}
\newtheorem{exercise}{Exercise}
\newtheorem{lemma}{Lema}
\newtheorem{notation}{Notat\c{c}\~ao}
\newtheorem{problem}{Problema}
\newtheorem{proposition}{Proposi\c{c}\~ao}
\newtheorem{remark}{Observa\c{c}\~ao}
\newtheorem{solution}{Solu\c{c}\~ao}
\newtheorem{summary}{Sum\'ario}
\newenvironment{proof}[1][Demonstra\c{c}\~ao]{\textbf{#1.} }{\ \rule{0.5em}{0.5em}\vspace{0.5cm}}
\newcommand{\usp}{Universidade de S\~{a}o Paulo}
\newcommand{\MakeIndex}{\textsl{MakeIndex}}
\newcommand{\itemnorma}[1]{\textit{#1}}
\newcommand{\ingles}[1]{\textsl{#1}}
\newcommand{\bibTeX}{bib\kern-.13ex\TeX}%
\newcommand{\abnt}{{\smaller ABNT}}%
\newcommand{\report}{{\smaller REPORT}}%
\newcommand{\xypic}{X\hspace*{-.2ex}\raisebox{-.5ex}{Y}-pic}%
 %\newcommand{\ac}{\symbol{123}}  % abre chaves
%\newcommand{\fc}{\symbol{125}}  % fecha chaves
\newcommand{\bs}{\symbol{92}}   % barra invertida (backslash)
\renewcommand{\ABNTtravessao}{}
\setlength{\ABNTanapindent}{0cm}
\renewcommand{\ABNTaposindicativoanap}
                    {\protect\\[4mm]\protect\centering}



% ***************************************
% *******Capa personalizada *************
% ***************************************



%---------------------------------------------------------------------

\providecommand{\ABNTvarautordata}{}
\let\oldautor\autor\relax
\renewcommand{\autor}[2][] {%
\renewcommand{\ABNTvarautordata}{#1}
\oldautor{#2}}

\renewcommand{\capa} {%
\begin{titlepage}
\makeheader
\begin{center}
\vfill
{
\Large\ABNTautordata}\\[2cm]
{\LARGE\textbf{\ABNTtitulodata}}\\[2cm]

\vfill
{\large \ABNTlocaldata \\ \ABNTdatadata}
\end{center}
\end{titlepage}}

% ***************************************
% ****Folha de rosto personalizada ******
% ***************************************


\renewcommand{\folhaderosto}{
\begin{titlepage}
	\vfill
	\begin{center}
		{\large \ABNTautordata}\\[5cm]
		{\LARGE \textbf{\ABNTtitulodata}}\\[2cm]
		\hspace{.45\textwidth}
		\begin{minipage}{.5\textwidth}
		\begin{espacosimples}
			\begin{small}
				\ABNTcomentariodata
				\\ \\
				%Ã?rea de ConcentraÃ§Ã£o: \ABNTareadata
%As duas linhas abaixo devem ser comentadas se nÃ£o houver necessidade de opÃ§Ã£o
				%\\
				%OpÃ§Ã£o: \ABNTopcaodata
%--------------------------------------------------------------------------------------------
				\\
				Orientador(a): \ABNTorientadordata
%As duas linhas abaixo devem ser comentadas se nÃ£o houver necessidade de co-orientador
				\\
				Co-orientador(a): \ABNTcoorientadordata
%--------------------------------------------------------------------------------------------
			\end{small}
		\end{espacosimples}
		\end{minipage}
		\vfill
		{\large \ABNTlocaldata \\ \ABNTdatadata}
	\end{center}
\end{titlepage}
}


%************************************
%**** Definições das referencias*****
%************************************

%\usepackage[num]{abntcite}
\usepackage[alf]{abntcite}
\usepackage{abnt-UFPR}
%\citebrackets[] % para que a citaçao apareça entre colhetes
%\newcommand*{\refname}{Referências Bibliográficas}








% ********************************
% ***** Início do Documento ******
% ********************************



\begin{document}

% DADOS PARA CAPA E FOLHA DE ROSTO
% Obs.: autor, título, local e data devem ser maiúsculas
% Para o título: em maiúscula apenas a primeira letra da sentença, exceto nomes próprios, geográficos, institucionais ou Programas ou Projetos ou siglas.


\instituicao{Universidade de São Paulo\\Escola de Artes, Ciências e Humanidades}
\autor{\uppercase{Lucas Fernandes Brunialti}}

\titulo{Biclusterização aplicada em Sistemas de Recomendação baseados em Conteúdo Textual}

\orientador{Profa. Dra. Sarajane Marques Peres}

\coorientador{Prof. Dr. Valdinei Freire da Silva}  %opcional. Se não houver coorientação, remover

%\coorientador{Co-orientador 1\protect\\Co-orientador 2}

\comentario{Texto de Exame de Qualificação apresentado à Escola de Artes, Ciências e Humanidades da Universidade de São Paulo como parte dos requisitos para obtenção do título de Mestre em Ciências pelo Programa de Pós-graduação em Sistemas de Informação. %Para texto de Exame de Qualificação, trocar esse texto por: Texto de Exame de Qualificação apresentado à Escola de Artes, Ciências e Humanidades da Universidade de São Paulo como parte dos requisitos para obtenção do título de Mestre em Ciências pelo Programa de Pós-graduação em Sistemas de Informação.
\newline
\newline
%Versão original.%Manter essa informação apensa em caso de versão de depósito da Dissertação de Mestrado
%Em caso de texto de Exame de Qualificação: remover essa informação 
%Em caso de versão definitiva da Dissertação de Mestrado: substituir essa informação por "Versão corrigida contendo as alterações solicitadas pela comissão julgadora em xx de xxxxxxxxxxxx de xxxx. A versão original encontra-se em acervo reservado na Biblioteca da EACH-USP e na Biblioteca Digital de Teses e Dissertações da USP (BDTD), de acordo com a Resolução CoPGr 6018, de 13 de outubro de 2011.", onde 'xx de xxxxxxxxxxxx de xxxx' é a 'data da defesa'
}

\local{São Paulo}

\data{2014} %/Para a versão definitiva da Dissertação de Mestrado: usar o ano de depósito da versão definitiva, e não o ano de defesa da Dissertação de Mestrado, caso eles sejam diferentes..

% ************* CAPA **************
% ********* SEM NUMERAÇÃO *********
\capa

% ******** FOLHA DE ROSTO *********
\folhaderosto



% ********** Autorização para Reprodução **********
% Página a ser incluída apenas em Dissertação de Mestrado (tanto na versão de depósito quanto na versão definitiva).
% 
% Solicitar a ficha catalográfica na Biblioteca da EACH. Duas versões devem ser solicitadas, em dois momentos distintos: 
% uma vez para a versão de depósito, e depois outra atualizada para a versão definitiva.

% IMPORTANTE: esta página de "autorização para reprodução e ficha catalográfica" deve ser impressa obrigatoriamente no verso da folha de rosto, de forma que ela não é contada como nova página.

% *********** OPCIONAL ************
\pretextualchapter{}

\begin{center}
Autorização para Reprodução

Ficha catalográfica
\end{center}
%\newpage

%********* FOLHA 	DE APROVAÇÃO*****
%
% Esta “Folha de Aprovação” já deve ser incluída na versão de depósito de Dissertação de Mestrado, 
% ou seja, ainda antes da aprovação propriamente dita, como uma previsão em caso de aprovação.
%
% Para isso, use os dados que certamente não mudarão, e deixe os demais sem preencher, na forma de um template.
%
% IMPORTANTE: Depois, para a versão definitiva da Dissertação de Mestrado aprovada, esta folha deverá ser substituída 
% por uma imagem digitalizada da folha oficial, com as assinaturas, fornecida pelo Serviço de Pós-graduação no dia da defesa.
%

%************************************


\begin{folhadeaprovacao}
\pretextualchapter{}
\begin{center}
Folha de Aprovação
\end{center}

\noindent Texto de Exame de Qualificação de Mestrado sob o título \textit{\textquotedblleft Biclusterização aplicada em Sistemas de Recomendação baseados em Conteúdo Textual\textquotedblright}, apresentado por Lucas Fernandes Brunialti e aprovado em \_\_\_ de \_\_\_\_\_\_\_\_\_\_\_\_\_ de \_\_\_\_\_, em São Paulo, Estado de São Paulo, pela comissão examinadora constituída pelos doutores: % Deixe a data em branco, pois a data pode mudar, mesmo que ela já esteja prevista.

% Para texto de Exame de Qualificação, trocar o texto acima por:
%
% Texto de Exame de Qualificação de Mestrado sob o título \textit{\textquotedblleft xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx xxxxxxxxxxxxxxxxxxxxx\textquotedblright}, apresentado por xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx e aprovado em \_\_\_ de \_\_\_\_\_\_\_\_\_\_\_\_\_ de \_\_\_\_\_, em São Paulo, Estado de São Paulo, pela comissão examinadora constituída pelos doutores:

\assinatura{Prof. Dr. \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ \\ Presidente \\ Instituição: \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_}
\assinatura{Prof. Dr. \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ \\ Instituição: \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_}
\assinatura{Prof. Dr. \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ \\ Instituição: \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_}
% Deixe em os nomes dos membros da banca em branco, pois os membros da banca podem mudar, mesmo que eles já estejam previstos.

\end{folhadeaprovacao}


% ********** DEDICATÓRIA **********
%Opcional para Dissertação de Mestrado (não sugerido para texto de Exame de Qualificação).
% *********** OPCIONAL ************
%\pretextualchapter{}

%\vspace{12cm}
%\hspace{.3\textwidth}
%\begin{minipage}{.6\textwidth}
%	\par Escreva aqui a sua dedicatória...
%	\par $\phantom{linha em branco}$
	
%\end{minipage}

%\newpage

% ******** AGRADECIMENTOS *********
%Opcional para Dissertação de Mestrado (não sugerido para texto de Exame de Qualificação).
% *********** OPCIONAL ************
%\pretextualchapter{}

%\vspace{12cm}
%\hspace{.3\textwidth}
%\begin{minipage}{.6\textwidth}
%	\par Escreva aqui os seus agradecimentos...
%	\newline
	%\par Minha família e aos meus amigos, por todo auxílio, paciência e compreensão que me deram durante o decorrer do projeto;
%	\end{minipage}

% *********** EPÍGRAFE ************
%Opcional para Dissertação de Mestrado (não sugerido para texto de Exame de Qualificação).
% *********** OPCIONAL ************
%\pretextualchapter{}

%\vspace*{12cm}
%\hspace{.3\textwidth}
%\begin{minipage}{.6\textwidth}

%\par Qualquer idéia que te agrade,
%\par Por isso mesmo... é tua.
%\par O autor nada mais fez que vestir a verdade
%\par Que dentro em ti se achava inteiramente nua...
%\par (Mário Quintana)
%\newline
%\par Por mais longa que seja a caminhada o mais importante é dar o primeiro passo.
%\par (Vinícius de Moraes)

	
%\end{minipage}

%************** - RESUMO - **********************
%Troque pelos seus dados os seguintes campos abaixo (mantendo a formatação e pontuação):
%
%SOBRENOME
%Nome1
%Nome2
%Nome3
%Título do trabalho
%Ano1 (Ano de Depósito da versão definitiva)
%NúmeroDePáginas (considerar da Introdução para frente, ou seja, desconsiderar as páginas iniciais na contagem)
%Ano2 (Ano de Defesa)
%
%Mantenha todas as demais informações exatamente como estão.
%
%[Não usar em caso de texto de Exame de Qualificação]
%
%************************************

\begin{resumo}
\begin{flushleft}
\noindent BRUNIALTI, Lucas Fernandes. \textbf{Biclusterização aplicada em Sistemas de Recomendação baseados em Conteúdo Textual}. 2015. NúmeroDePáginas f. Dissertação (Mestrado em Ciências) -- Escola de Artes, Ciências e Humanidades, Universidade de São Paulo, São Paulo, Ano2.
\newline
\end{flushleft}


\noindent Biclusterização representa uma estratégia de análise de dados com potencial para encontrar grupos de objetos similares considerando a correlação parcial existente entre os atributos descritivos dos mesmos. Esse potencial pode ser particularmente útil para Sistemas de Recomendação baseados em conteúdo, nos quais se faz necessária a sugestão de itens úteis, porém diversificados, para um usuário. Esta necessidade configura-se como um problema de serendipidade, uma das propriedades de Sistemas de Recomendação. O objetivo deste trabalho é analisar a aderência dos resultados provenientes de algoritmos de biclusterização, aplicados aos itens a serem recomendados, à meta de otimização da serendipidade. Para alcançar tal objetivo, este trabalho propõe um estudo da aplicação de algoritmos clássicos de biclusterização à conteúdo textual referente ao escopo de um Sistema de Recomendação de notícias. Ainda, este trabalho propõe a utilização de \emph{essembles} como uma forma alternativa de encontrar biclusters. A hipótese defendida é que devido à análise de correlações parciais dos atributos descritivos dos dados, seria possível encontrar notícias com similaridades parciais entre si devido às particularidades presentes nas mesmas. Desta forma, uma mesma notícia que cobre mais de um contexto poderia ser recomendada a usuários que estariam, à princípio, interessandos em assuntos diferentes.
Como forma de avaliação dos resultados obtidos, é proposta uma análise comparativa entre os resultados da recomendação obtida via biclusterização e os resultados de recomendação obtida via filtro colaborativo, onde o problema da serendipidade é reconhecidamente bem resolvido.
\end{resumo}

% redigido em parágrafo único, contendo no máximo 500 palavras, e apresentar os objetivos, metodologia, resultados e conclusões.

\par
\vspace{2em}
\noindent \textbf{Palavras-chave}: Biclusterização. Sistemas de Recomendação. Recomendação de Notícias. Mineração de Textos. \emph{Essembles}.


%**************** ABSTRACT ***********************
%Troque pelos seus dados os seguintes campos abaixo (mantendo a formatação e pontuação):
%
%SURNAME
%FirstName1
%MiddleName1
%MiddleName2
%Work title
%Year1 (Ano de Depósito da versão definitiva)
%NumberOfPages (considerar da Introdução para frente)
%Year2 (Ano de Defesa)
%
%Mantenha todas as demais informações exatamente como estão.
%
%[Não usar em caso de texto de Exame de Qualificação]
%
%***************************************


\begin{abstract}
\begin{flushleft}
\noindent BRUNIALTI, Lucas Fernandes. \textbf{Work title}. 2015. NumberOfPages p. Dissertation (Master of Science) -- School of Arts, Sciences and Humanities, University of São Paulo, São Paulo, Year2.
\newline
\end{flushleft}


\noindent Write here the English version of your \textquotedblleft Resumo \textquotedblright...
\end{abstract}

\par
\vspace{2em}
\noindent \textbf{Keywords}: Keyword1. Keyword2. Keyword3. Etc.

% 1 - Lista de Figuras
\listoffigures

% 2 - Lista de Tabelas
\listoftables

%\part{teste}


% ************ SUMÁRIO ************
\tableofcontents
% ************ LISTAS *************
% ** Condicionadas à necessidade **


\chapter{Introdução}
\label{intro}

%\pagenumbering{arabic} 
%\lhead[\fancyplain{}{\helv\thepage}] 
%{\fancyplain{}{\helv\rightmark}} 
%\rhead[\fancyplain{}{\helv\leftmark}] 
%{\fancyplain{}{\helv\thepage}} 
%\pagestyle{fancy}
%\fancyhead[RO,RE]{\helv\thepage}
%\fancyhead[LO,LE]{\it\nouppercase\leftmark}
%\fancyfoot{}


Sugestão: fazer uma introdução contextualizada em um probema de recomendação de notícias. Para esse problema, criar um cenário onde uma notícia poderia ser recomendada para dois usuários diferentes que estariam inicialmente navegando em notícias diferentes (de contextos diferentes). Mostrar que uma notícia pode estar relacionada a duas outras que por sua vez não estão relacionadas.

\textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}

\textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}

\textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}

\section{Apresentação do Problema de Recomendação}

Apresentar de maneira mais formal (acima foi só um cenário), o problema de recomendação. Tentar caracterizar (aí acho que de maneira não formal necessariamente) a propriedade de serendipidade.

\textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}

\section{Apresentação do contexto de Biclusterização}

Apresentar o que é biclusterização, em linhas gerais e com uma pequena formulação. Falar que existem vários algoritmos.

\textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}

\textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}

Apresentar em linhas gerais a possibilidade de implementar bicluterização usando a alternativa de essemble.

\textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}

\textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}

\section{Hipótese}

% Apresentar a nossa hipótese de que se juntar biclustering com recomendação vai resolver serendipidade.

% \textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}

Um grande problema referente à SRs baseados em conteúdo é a sobre-especialização, que é a falta de recomendações com conteúdo novo ou inesperado à um usuário, ou a falta de serendipidade nas recomendações. Como a Biclusterização é capaz de expandir o espaço de busca, levando em consideração subconjuntos das características para a formação de clusters, a hipótese desse projeto é que a aplicação de algoritmos de biclusterização em SRs baseados em conteúdo pode amenizar o problema de sobre-especialização, melhorando a qualidade das recomendações e contribuindo para a área de SRs.


\section{Objetivos}

% Colocar o objetivo de resolver o problema acima, otimizando a serendipidade, através do uso de biclusterização nos documentos (notícias).
O objetivo geral desse trabalho é amenizar o problema da serendipidade em SRs baseados em conteúdo textual, no domínio de notícias. Isso será possível através da aplicação de algoritmos de biclusterização nessas notícias, fazendo uso de diversas representações para estruturação do conteúdo textual.

Assim, foram estabelecidos os seguintes objetivos específicos:

\begin{itemize}
 \item levantamento do referencial teórico de sistemas de recomendação textual
 \begin{itemize}
  \item levantamento do estado da arte (sua revisao sistemática)
 \end{itemize}
 \item levantamento de referencial teórico de biclustering
 \item construção de um conjunto de dados
 \item estudo de processamento de texto (text mining)
 \item estudo das técnicas de biclustering aplicadas à texto
 % \item estudo das técnicas de essemble aplicadas a texto
\end{itemize}

\section{Metodologia}

Aqui explicar cada um dos passos. Explicar que o levantamento do referencial teórico através de análise exploratória. Explicar como é a revisão sistemática (um parágrafo). Explicar a motivação de tê-la realizado. \textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}

Explicar como o conjunto de dados foi construído. Explicar a base de cliques. \textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}

Explicar que as técnica de biclustering e essemble serão aplicadas aos textos processados e que uma avaliação será feita com base nas informações de cliques. \textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}

\section{Organização do documento}

Este documento é composto por X capítulos incluindo esta introdução. O Capítulo 1 ..... e apresentar cada um. \textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}

\chapter{Conceitos Fundamentais}

Este capítulo introduz os conceitos fundamentais para o entendimento dessa dissertação, fazendo um apanhado dos conceitos na área de Sistemas de Recomendação (seção~\ref{cf:sr}), Biclusterização (seção~\ref{cf:bicl}) e Mineração de Texto (seção~\ref{cf:mt}).

\section{Sistemas de Recomendação}
\label{cf:sr}

% provavelmente vou ter que fazer o bib de tese-chap2: http://tampub.uta.fi/bitstream/handle/10024/95965/978-951-44-9551-9.pdf
A grande maioria das pessoas que usam a Internet muito provavelmente já interagiram com algum Sistema de Recomendação (SR), por isso, o seu conceito é intuitivo.
Porém, por ser uma área relativamente nova \cite{Lops2011}, muitos autores não usam uma definicão que reflete a realidade dos SRs, isso acontece por ser uma área relativamente nova que teve um crescimento muito grande nos últimos anos (tese-chap2).

\citeonline{Resnick1997}, quem criou o termo Sistemas de Recomendação (tese-chap2) \cite{Neumann2007}, argumentam que Sistemas de Recomendação servem para nos ajudar em processos de tomada de decisão do nosso dia-a-dia, como quais itens comprar, quais músicas ouvir, ou quais notícias ler.
Além disso, \citeonline{Resnick1997} provê uma taxonomia para definição de Sistemas de Recomendação:
\begin{itemize}
  \item Conteúdo recomendado: os itens que são recomendados pelo Sistema de Recomendação, ex: produtos, músicas, notícias e/ou etc.
  \item Entrada dos usuários: as interações que os usuários realizam com os itens são a entrada para um SR, estas podem ser implícitas (ex: o usuário $x$ leu a notícia $y$) ou explícitas (ex: o usuário $x$ classificou o filme $y$ como $5$ estrelas).
  \item Target of recommendation: os itens recomendados podem ser diretamente para um usuário (personalizado), direcionados para um grupo de usuários ou todos os usuários (não-personalizado).
  \item Técnicas para recomendação (agregações): qual as estratégias e os algoritmos que os SRs usam para criar recomendações.
  \item Uso das recomendações: trata-se de como mostrar as recomendações para os usuários, ex: filtrando recomendações negativas, ordenando pelo fator numérico, etc.
\end{itemize}

Porém, definições mais recentes \cite{Burke2002,Burke2007}, descrevem SRs como qualquer sistema que produz recomendações personalizadas ou tem o efeito de guiar um usuário de modo personalizado, mostrando itens que possam ser interessantes para este usuário, dentro de uma grande quantidade de opções.
Isso faz com que SRs que provêm recomendações não personalizadas deixem de adequar com a definição de SR.
É provável que isso se deve ao fato que das estratégias usadas atualmente, que têm o foco de produzir recomendações personalizadas.

Formalmente, \citeonline{Burke2002,Burke2007} define SRs como um conjunto de itens $I$  que podem ser recomendados e um conjunto de usuários $U$ que as preferências são conhecidas, um usuário $u$ pra o qual as recomendações são geradas, e algum item $i$ que queremos predizer a preferência para $u$.
\citeonline{Adomavicius2005} extende a definição com uma função de utilidade $f$ que mede o quão útil é o item $i$ para o usuário $u$: $f: I \times U \rightarrow R$, em que $R = \{ r_{u_1,i_1}, r_{u_1,i_2}, \dots, r_{u_1,i_m}, \dots, r_{u_1,i_m} \}$ é um conjunto ordenado com valores faltantes, sendo $r_{u_i,i_j}$ um inteiro ou real que representa a interação do usuário $u_i$ no item $i_j$.
No entanto, existem tipos de SRs que não estimam $f$ completamente, podendo otimizar funções auxiliares para gerar as recomendações para um usuário $u$ \cite{Lops2011}.

Em síntese, um Sistema de Recomendação tem a função de auxiliar os usuários de uma aplicação à interagir com itens, provendo sugestões de quais itens interagir, baseando-se no histórico de interações desses usuários com esses itens.

 \subsection{Tipos de Sistemas de Recomendação}
 \label{sec:tipos}

Para estimar $f$ e chegar no conjunto ordenado $R$ existem diversas estratégias, daí surgem os tipos de SRs.
Os tipos de SRs diferem quanto ao domínio, informações usadas para recomendação, algoritmos \cite{Feldman2006}, e principalmente nas propriedades em que cada tipo se destaca.

% Não sei se coloco a taxonomia tradicional, ou se coloco essa, handbook-1 diz que é clássica, podem burke de 2002 para 2007 muda a taxonomia, enquanto isso, Adomavicius usa a tradicional e o livro usa a tradicional + baseado em conhecimento
\citeonline{Burke2002,Burke2007} provê uma taxonomia já considerada clássica \citeonline{Lops2011}, que categoriza os SRs em cinco diferentes tipos:
\begin{itemize}
 \item \textit{Filtragem colaborativo}, o primeiro tipo de SR que foi implementado \cite{Resnick1997}, tem como idéia básica encontrar outros usuários $u_{1,\dots,n}$ em $U$, sendo $n < |U|$ e não necessariamente em ordem, com preferências semelhantes à $u$, e então recomendar itens que $u_{1,\dots,n}$ interagiram e que $u$ ainda não interagiu, estabelecendo alguma métrica para estimar $f$. Medidas geralmente usadas incluem \textit{Correlação de Pearson} e \textit{Similaridade dos Cossenos}, também são usados técnicas para redução de dimensionalidade, como \textit{Decomposição de Valores Singulares} e \textit{Fatorização de Matriz} \cite{Jannach2011}.
 \item \textit{Baseado em conteúdo}, é um dos tipos de SR que otimiza funções auxiliares à $f$. Descreve os itens por características possibilitando o uso de medidas de similaridade entre itens. Então, com as interações dos usuários de $U$ sob itens em $I$, é construído um perfil de interesses para cada usuário. As recomendações são feitas a partir da combinação do perfil de interesses de um usuário $u$ com os itens em $I$ que $u$ ainda não interagiu. Neste caso são usadas técnicas de Recuperação de Informação \cite{Jannach2011} para representar os itens e calcular similaridades entre itens, assim como técnicas de Aprendizado de Máquina Supervisionado e não-supervisionado \cite{Jannach2011,Burke2002}.
 % \item Demográfico, considera atributos demográficos de cada usuário, estimando $f$ a partir dessas informações. Neste tipo também são usadas técnicas de Aprendizado de Máquina Supervisionado para classificar usuários em diferentes classes demográficas.%constrói recomendações personalizadas com base no perfil demográfico de usuários
 \item \textit{Baseado em Conhecimento}, tem o intuito de sugerir itens, de forma personalizada, baseando-se nas necessidades ou regras estabelecidas por um usuário $u$ e nas características dos itens em $I$. São estabelecidas medidas de similaridade para estimar o quanto as necessidades do usuário match as recomendações \cite{Jannach2011,Lops2011,Burke2007}.
 \item \textit{Híbrido}, é capaz de combinar as vantagens de cada tipo de SR descrito para suprir as limitações associadas à cada tipo. A dificuldade esta em como combinar as diferentes técnicas de cada algoritmo \cite{Jannach2011,Burke2007}. \citeonline{Burke2007} identificou 7 tipos de SRs Híbridos em uma revisão da literatura: Pesagem, atribui um peso para cada algoritmo; Switching, seleciona um dos algoritmos (ou tipos); Mixed, recomendações são mostradas em conjunto; Combinação de características, diferentes fontes são combinadas em apenas um algoritmo; Feature Augumentation, uma técnica é usada para computar características que servem de entrada para outra técnica; Cascade, é atribuído um grau de prioridade para cada algoritmo; Meta-level, uma técnica gera um modelo, que é usado como entrada para outras técnicas.
\end{itemize}

 \subsubsection{Vantagens e desvantagens}
 \label{sec:lim}

Cada um dos tipos de SRs descritos possuem algumas limitações independentes se comparados com os outros tipos ou não.
Em \citeonline{Jannach2011,Adomavicius2005,Burke2002,Lops2011} são nomeadas os problemas no desenvolvimento de SRs de \textit{novo usuário} (\textit{user cold-start}), \textit{novo item} (\textit{item cold-start}), \textit{esparsidade}, \textit{sobre-especialização} e \textit{análise de conteúdo limitada} referentes aos SRs.

Os problemas de \textit{novo usuário} e \textit{novo item} são similares, basicamente, enquanto o primeiro se trata da dificuldade de gerar recomendações para novos usuários, o segundo se trata de gerar recomendações para novos itens.
O problema de \textit{novo usuário} esta presente como uma desvantagem nos SRs de filtragem colaborativa e baseado em conteúdo, pois o SR não conhece as preferências dos novos usuários, tendo dificuldade de construir um modelo que tem como base essas preferências.
Já o problema de \textit{novo item} é considerado uma vantagem para os SRs baseados em conteúdo, enquanto uma desvantagem para os SRs baseados em filtragem colaborativa.
Como a filtragem colaborativa se baseia apenas nas interações de usuários em itens, um item novo, que não teve ou teve poucas interações, não será recomendado, diferentemente do SR baseado em conteúdo, que leva em consideração a representação do item para construir recomendações.

Contrariamente, o problema de \textit{sobre-especialização} é uma vantagem para os SRs de filtragem colaborativa e uma desvantagem para os SRs baseados em conteúdo.
A \textit{sobre-especialização} diz respeito ao problema de sugerir apenas itens previsíveis para o usuário, por exemplo, se o usuário viu notícias apenas de esporte, ele já espera receber sugestões de notícias de esporte, porém este usuário muito provavelmente pode gostar de ler notícias de outras categorias.
A capacidade do SR de sugerir notícias imprevisíveis é chamado de \textit{serendipidade} \cite{Jannach2011,Lops2011}.
SRs baseados em conteúdo sofrem desse problema pois combina o perfil de preferências de um usuário com os itens em $I$, restrigindo o espaço de busca para realizar a sugestão de itens.
Enquanto isso, os SRs baseados em filtragem colaborativa são capazes de oferecer sugestões úteis e serendipitas, pois são capazes de ampliar o espaço de busca através da estratégia de sugerir itens que usuários semelhantes à $u$ interagiram e que $u$ ainda não interagiu.

Os SRs baseados em filtragem colaborativa são os únicos que sofrem do problema de \textit{esparsidade}, que é o fato de usuários interagirem com apenas um pequeno subconjunto do conjunto de itens, tornando a matriz de interações ou preferências ($U \times I$) esparsa.
Isso faz com que aumente a necessidade de ter uma grande quantidade de usuários, pois este tipo de SR necessita de intersecções nas interações de itens por usuários, para que seja possível encontrar usuários similares a um dado usuário.

Assim como os SRs de filtragem colaborativa, os SRs baseados em conteúdo sofrem de um problema único, que é a \textit{análise de conteúdo limitada}.
Este problema se refere à representação dos itens, que tem de ser suficiente para discriminá-los \cite{Lops2011}.
Em SRs baseados em conteúdo é comum ter que limitar a representação de itens, tanto pelo número de características quanto pela modelagem.
Por exemplo, no contexto de notícias na web, se a representação for um vetor com o número de ocorrências de cada palavra, perdemos a relação entre as palavras, e também todo o conteúdo que não é texto, como imagens, vídeos, etc.

 \subsection{Avaliação da Recomendação}

Diferentes técnicas foram mostradas e uma variedade de problemas relacionados à essas técnicas, mas como avaliar se uma estratégia adotada no desenvolvimento realmente é efetiva?
SRs podem ser avaliados através de \textit{experimentos online}, que podem descobrir a real influência do SR no comportamento do usuário, e \textit{experimentos offline}, que estimam o erro de predição e simulam o comportamento do usuário no SR usando um conjunto de dados \cite{Ricci22011}.

Para experimentos online podem ser estabelecidas variáveis através da captura implícita ou explícita do comportamento, como satisfação do usuário e taxa de cliques (\textit{click-through rate} - CTR).
Uma das maneiras para realizar esse tipo de experimento é por meio de testes A/B \cite{Jannach2011}, em que cada usuário, ao interagir com o SR, recebe um tratamento diferente aleatóriamente, dentro dos possíveis tratamentos estabelecidos pelo experimento.
Assim, é possível dizer, por exemplo, a influência de um novo componente no SR no comportamento dos usuários.

Tradicionalmente, SRs são avaliados através de experimentos offline \cite{Jannach2011}.
Por serem simples, esses tipos de experimentos podem ser usados para para selecionar algoritmos, no entanto, \citeonline{Ricci22011} argumentam que não é possível medir diretamente a influência das recomendações no comportamento dos usuários.
Para simular o comportamento do usuário em um SR usando um conjunto de dados, são estabelecidos dois subconjunto das interações de $u$ aleatoriamente ($\{ r_{u,i_4}, r_{u,i_3}, \dots \}$), um para treinamento dos modelos $\text{conj treino}_u$ e outro para teste $\text{conj teste}_u$.
Assim é possível adotar estratégias semelhantemente com às adotadas em Aprendizado de Máquina, como \textit{matriz de confusão}, \textit{precisão}, \textit{revocação}, \textit{f1-score}, \textit{cross-validation} e etc.
A técnica de \textit{matriz de confusão} é possível ser usada em \textit{experimentos online} e \textit{offline}, da seguinte maneira: se o usuário gostar do item sugerido à ele, é considerada uma predição correta (verdadeiro positivo); se o usuário não solicita preferência pela sugestão ou se não existe informações da preferência do usuário para esta sugestão, será considerada uma predição errada (falso positivo); contrariamente, se o SR não fazer essas sugestões, é considerada uma emissão correta (verdadeiro negativo); por fim, se o SR não sugerir itens que o usuário tem preferência, é consuderada uma predição errada (falso negativo).

Uma das métricas mais comuns usadas para \textit{experimentos offline} é o \textit{erro absoluto médio} (\textit{Mean Absolute Error} - MAE) e \textit{raiz do erro quadrático médio} (\textit{Root Mean Squared Error} - RMSE) \cite{Jannach2011}, o qual foi usado como métrica para a competição Netflix Prize\footnote{http://www.netflixprize.com/}, que teve grande repercursão na academia e na indústria. A defição formal das métricas MAE e RMSE são descritas nas equações~\ref{eq:mae} e~\ref{eq:rmse}, respectivamente.

\begin{equation}
\label{eq:mae}
MAE = \sum_{u \in U} \frac{\sum_{i \in \text{conj teste}_u} |f(u,i) - r_{u,i}|}{|\text{conj teste}_u|}
\end{equation}

\begin{equation}
\label{eq:rmse}
RMSE = \sum_{u \in U} \sqrt{\frac{\sum_{i \in \text{conj teste}_u} (f(u,i) - r_{u,i}^2}{|\text{conj teste}_u|}}
\end{equation}

A métrica MAE computa o erro médio entre as predições feitas pelo SR ($f(u,i)$) e os valores reais das preferências dos usuários ($r_{u,i}$) para todos os usuários em $U$, enquanto o RMSE amplifica erros grandes, pois eleva o mesmo ao quadrado. Essas métricas são usadas para valores reais, ou seja, $r_{u,i} \in [0,1]$, por exemplo.

Para valores binários de $r_{u,i}$ ou quando deseja-se prever o número de recomendações relevantes para um usuário $u$, são usadas as métricas \textit{precisão} e \textit{revocação} \cite{Jannach2011}.

Para medir a serendipidade das recomendações, \citeonline{Ricci22011} propõem uma estratégia: estabelecer uma medida de distância entre itens e rotular os itens com menor distância entre si como ausentes de serendipidade, assim, algoritmos que evitem esses itens, serão considerados superiores.

\section{Biclusterização}
\label{sec:bic}

% Um parágrafo com definição geral. \textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}

Técnicas e algoritmos de biclusterização são usadas, principalmente, no contexto de expressão genética.
No entanto, algoritmos de biclusterização se fazem útil quando se deseja encontrar \textit{modelos locais}.
Ou seja, enquanto algoritmos de clusterização têm o intuito de encontrar \textit{modelos globais}, que geram grupos de dados levando em consideração todas as características, algoritmos de biclusterização geram grupos de dados em que as características tem alta correlação \cite{Madeira2004}.

Para a descrição do problema formal de biclusterização usa-se a seguinte definição \cite{Madeira2004}: uma matriz $A$, $n \times m$, um conjunto de linhas $X = \{ x_1, \dots, x_n \}$ e um conjunto de colunas $Y = \{ y_1, \dots, y_m \}$, em que $a_{ij}$, geralmente um número real, e representa a relação entre a linha $x_i$ e a coluna $y_j$.
O problema de biclusterização é encontrar biclusters, que são submatrizes de $A$, denotados por $A_{IJ}$, em que $I \subseteq X$ e $J \subseteq Y$.
Assim, o bicluster $A_{IJ}$ é um grupo dos exemplos em $I$, perante as características com alta correlação $J$.

   \subsection{Tipos de biclusters}
   \label{sec:tiposbic}

	Como a definição de bicluster não inclui uma prévia estrutura da matriz $A$ e dos biclusters $A_{IJ}$, diversos algoritmos propostos na literatura diferem quanto ao tipo de bicluster que são capazes de encontrar. Uma taxonomia dos tipos de biclusters é proposta por \citeonline{Madeira2004}:
	 \begin{itemize}
	  \item \textit{Biclusters com valores constantes}, se trata de biclusters em que todos os valores de $A_{IJ}$ são constantes: $a_{ij} = \mu, \forall i,j \in I,J$, onde $\mu$ é um valor constante dentro de $A_{IJ}$. Porém, em conjuntos de dados reais, esses biclusters estão presentes com algum tipo de ruído $\mu + \eta_{ij}$, onde $\eta_{ij}$ é o ruído associado com os valures de $\mu$ e $a_{ij}$ \cite{Madeira2004}.
	  \item \textit{Biclusters com valores constantes nas linhas ou colunas}, se trata de biclusters com valores constantes nas linhas: $a_{ij} = \mu + \alpha_i, \forall i,j \in I,J$ ou $a_{ij} = \mu \cdot \alpha_i, \forall i,j \in I,J$, onde $\alpha_i$ é um fator aditivo ou multiplicativo para cada linha; ou ainda biclusters com valores constantes nas colunas: $a_{ij} = \mu + \beta_j, \forall i,j \in I,J$ ou $a_{ij} = \mu \cdot \beta_j, \forall i,j \in I,J$, onde $\beta_j$ é um fator aditivo ou multiplicativo para cada coluna \cite{Madeira2004}.
	  \item \textit{Biclusters com valores coerentes}, em que são considerados valores próximos entre si (coerentes) para definição de um bicluster: $a_{ij} = \mu + \alpha_i + \beta_j, \forall i,j \in I,J$, ou $a_{ij} = \mu' \cdot \alpha_i' \cdot \beta_j', \forall i,j \in I,J$, sendo que se $\mu = \log \mu'\implies \alpha_i = \alpha_i', \beta_j = \beta_j'$ \cite{Madeira2004}.
	  \item \textit{Biclusters com evoluções coerentes}, têm seus valores com evoluções coerentes, por exemplo, um bicluster com $a_{i4} \leq a_{i3} \leq a_{i2} \leq a_{i1}$ tem valores com evolução coerente na coluna \cite{Madeira2004}. Seus valores podem ser gerados por uma função geradora de valores com evolução coerente $a_{ij} = g(a_{ij}), \forall i,j \in I,J$, sendo $g(\cdot)$ não linear e não constante, para que o tipo de bicluster não seja classificado nos casos anteriores.
	 \end{itemize}
	
	Os biclusters também se diferem quanto a sua estrutura, cada algoritmo faz uma suposição da estrutura de biclusters que é capaz de encontrar. A Figura~\ref{fig:bicstruct} sumariza as diferentes estruturas de biclusters, com as linhas e colunas ordenadas, para permitir a visualização dos biclusters por meio do mapa de calor dos valores de $A$.

	\begin{figure}[H]
        % \captionsetup[subfigure]{labelformat=simple}
        \centering
        \begin{subfigure}[b]{0.3\textwidth}
                \includegraphics[width=30mm]{img/a-bic-struct.png}
                \caption{Bicluster único}
                \label{fig:bicstruct-a}
        \end{subfigure}
        ~
        \centering
        \begin{subfigure}[b]{0.3\textwidth}
                \includegraphics[width=30mm]{img/b-bic-struct.png}
                \caption{Biclusters com linhas e colunas exclusivas}
                \label{fig:bicstruct-b}
        \end{subfigure}
        ~
        \centering
        \begin{subfigure}[b]{0.3\textwidth}
                \includegraphics[width=30mm]{img/c-bic-struct.png}
                \caption{Biclusters com estrutura de tabuleiro de xadrez}
                \label{fig:bicstruct-c}
        \end{subfigure}
        ~
        \centering
        \begin{subfigure}[b]{0.3\textwidth}
                \includegraphics[width=30mm]{img/d-bic-struct.png}
                \caption{Biclusters com linhas exclusivas}
                \label{fig:bicstruct-d}
        \end{subfigure}
        ~
        \centering
        \begin{subfigure}[b]{0.3\textwidth}
                \includegraphics[width=30mm]{img/e-bic-struct.png}
                \caption{Biclusters com colunas exclusivas}
                \label{fig:bicstruct-e}
        \end{subfigure}
        ~
        \centering
        \begin{subfigure}[b]{0.3\textwidth}
                \includegraphics[width=30mm]{img/f-bic-struct.png}
                \caption{Biclusters sem sobreposição com estrutura em árvore}
                \label{fig:bicstruct-f}
        \end{subfigure}
        ~
        \centering
        \begin{subfigure}[b]{0.3\textwidth}
                \includegraphics[width=30mm]{img/g-bic-struct.png}
                \caption{Biclusters sem sobreposição e não exclusivos}
                \label{fig:bicstruct-g}
        \end{subfigure}
        ~
        \centering
        \begin{subfigure}[b]{0.3\textwidth}
                \includegraphics[width=30mm]{img/h-bic-struct.png}
                \caption{Biclusters com sobreposição com estrutura hierarquica}
                \label{fig:bicstruct-h}
        \end{subfigure}
        ~
        \centering
        \begin{subfigure}[b]{0.3\textwidth}
                \includegraphics[width=30mm]{img/i-bic-struct.png}
                \caption{Biclusters com sobreposição arbitrariamente posicionados}
                \label{fig:bicstruct-i}
        \end{subfigure}
        \caption{Diferentes estruturas de biclusters, quadrados com cores sólidas representam biclusters (Adaptado de \cite{Madeira2004})}
        \label{fig:bicstruct}
	\end{figure}
	
	\subsection{Algoritmos para biclustering}

	Diversos algoritmos para encontrar biclusters, de diferentes tipos e estruturas, foram propostos na literatura \cite{Tanay2005,Madeira2004}.
	
	Um dos mais comuns e simples algoritmos de biclusterização, que encontra biclusters com valores coerentes e estrutura com sobreposição e arbitrariamente posicionados, é o \textit{Coupled Two-way Clustering} (CTWC) \cite{Getz2000}, pois encontra biclusters através da clusterização de características e exemplos (linhas e colunas), separadamente.
	O algoritmo de clusterização usado por \cite{Getz2000} foi o \textit{Superparamagnetic Clustering} (SPC), pois é capaz de determinar o número de clusters automaticamente e com uma estratégia de clusterização hierárquica \textit{top-down} é capaz de gerar clusters estáveis \cite{Getz2000}.
	O SPC tem como entrada uma matriz de similaridade e um parâmetro temperatura, que controla o quão estáveis serão os clusters que o algoritmo irá gerar.
	Assim, o CTWC encontra clusters estáveis de linhas e colunas através do SPC, e iterativamente, performa o SPC novamente nos clusters de linhas e colunas encontrados, mantendo na memória um par do subconjunto de linhas e do subconjunto de colunas (biclusters), assim como os clusters estáveis de linhas e colunas, separadamente.





 It uses a heuristic to avoid brute-force
enumeration of all possible combinations: Only subsets of
rows or columns that are identified as stable clusters in
previous clustering iterations are candidates for the next
iteration. CTWC begins with only one pair of rows and
columns, where each pair is the set containing all rows and
the set that contains all columns, respectively.


	A hierarchical
clustering algorithm is applied on each set generating
stable clusters of rows and columns, and consequently a set
of biclusters at a time

	- euclidiana para medida de dissimilaridade

	% \textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}
	
	% \textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}
	
	% \textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}
	
	 \subsection{Avaliação de biclustering}
	
	\textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}
	
	\textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}

% 	 \subsection{Essembles para clusterização}

% \textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}

% \textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}

% \textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}
		
\section{Mineração de Texto}

Técnicas de Mineração de Texto são muito usadas para SRs baseados em conteúdo textual \cite{Lops2011}, principalmente quando o contexto do SR se trata de informações não-estruturadas. Mineração de Texto lida com análise de texto, suportando a sua natureza não-estruturada, imprecisa, incerta e difusa, para extração de informação e conhecimento \cite{Hotho2005}. Além disso, a área de Mineração de Texto utiliza de técnicas das áreas de Recuperação de Informação, Processamento de Linguagem Natural (PLN), conectando essas técnicas com algoritmos e métodos de Descoberta de Conhecimento em Banco de Dados, Mineração de Dados, Aprendizado de Máquina e Estatística \cite{Hotho2005}.

% MOTIVAÇAO (?)

\citeonline{Feldman2006}, apresentam uma arquitetura geral para aplicações de Mineração de Textos composta por quatro etapas: tarefas de pré-processamento, que preparam os dados para a central de operações de mineração; central de operações de mineração, incluem algoritmos para a descoberta de padrões, tendências e conhecimentos através de técnicas e algoritmos; componentes de apresentação, incluem interfaces para o usuário apresentando visualizações dos conhecimentos gerados na etapa anterior; e técnicas de refinamento, também descrito como uma fase de pós-processamento, que inclui métodos para filtrar informações redundantes.

	\subsection{Tarefas de pré-processamento}

	As tarefas de pré-processamento incluem rotinas, processos e métodos para a estruturação dos textos presentes nos documentos.
	A estruturação se faz necessária para a extração de informações e descoberta de conhecimento por meio de técnicas e algoritmos \cite{Hotho2005}.

	\subsubsection{Representação textual}

	Para a estruturação dos textos é necessário a definição da representação textual dos documentos.
	O vetor de palavras, ou Vector Space Model \cite{Salton1975}, é a representação clássica usada para representar documentos textuais (referencia). Cada dimensão desse vetor esta associado à palavra, sendo que todas as dimensões representam todas as palavras do conjunto de documentos.
	Formalmente, temos um conjunto de documentos $D = \{ d_1, d_2, \dots, d_n \}$, em que $d_i$ representa um documento e $n$ o número total de documentos, e um conjunto de palavras $P = \{ p_1, p_2, \dots, p_m \}$, em que $p_j$ representa uma palavra e $m$ o número de palavras presentes em todos os documentos.
	Representando a frequência de uma palavra, o número de vezes que $p_j$ aparece em um documento $d_i$, por $fp(p_j, d_i)$, o vetor de palavras pode ser construído e representado da seguinte forma: $\vec{vp}_{d_i} = ( fp(p_1, d_i), fp(p_2, d_i), \dots, fp(p_m, d_i) )$.
	\citeonline{Salton1975} argumenta que a representação textual de documentos em vetor de palavras é suficiente para separar documentos.
	Ao invés de frequência de palavra, também é comumente usado, a representação binária (referencia), ou seja, $p_j$ aparecendo em $d_i$ corresponde à entrada $1$ na dimensão $j$ em $\vec{vp}_{d_i}$.
	Há também outros métodos para representação textual, como \textit{n-gramas} e \textit{ontologias}.

	Ainda sobre o vetor de palavras, \citeonline{Salton1975} mostra com experimentos em diversos conjuntos de dados, que o uso da normalização nos vetores usando a técnica de Frequência de Palavras-Frequência de Documentos Inversa (\textit{Term Frequency-Inversed Document Frequency} - TFIDF) é capaz de melhorar a separação de documentos:
	\begin{equation}
	\begin{split}
		\text{\textit{fp-fdi}}(p_j, d_i) = fp(p_j, d_i) \cdot fdi(p_j) \\
		\text{\textit{fp-fdi}}(p_j, d_i) = fp(p_j, d_i) \cdot \left( log_{2} \frac{n}{fd(p_j) + 1} \right)
	\end{split}
	\end{equation}
	em que $fdi(p_j)$ representa a Frequência de Documentos Inversa da palavra $p_j$ e $fd(p_j)$ a frequência de documentos que contém $p_j$. Essa normalização faz com que a frequência das palavras que aparecem em muitos documentos seja reduzida, e a frequência das palavras que aparecem em alguns raros documentos seja aumentada, com um fator de $\log_{2}$.

	\subsubsection{Tokenização}

	Para realizar a estruturação de textos e representar os textos dos documentos em vetores de palavras, o primeiro processo a ser realizado é a \textit{tokenização}, que cria um dicionário de palavras para cada documento através da quebra dos textos desses documentos. A quebra do texto pode ser feita através de caracteres delimitadores de termos, como espaços em branco, pontuações e etc. No entanto, existem casos que esses caracteres podem não ser delimitadores de termos, como por exemplo os termos \textit{Prof.} e \textit{Sr.}. Este problema é chamado de determinação de fim de sentença, e pode ser resolvido por métodos estáticos (\textit{hard-coded}), baseados em regras e métodos de Aprendizado de Máquina \cite{Weiss2010}.

	\subsubsection{Filtragem}

	Métodos de filtragem têm a função de retirar palavras do conjunto $P$ que não contribuem para distinguir ou identificar documentos, como exemplo, conjunções (\textit{e}, \textit{pois}, \textit{que}), artigos (\textit{um}, \textit{o}, \textit{a}), preposições (\textit{de}, \textit{para}) e etc.
	A técnica de retirar determinadas palavras de $P$ a partir de uma lista, é chamada de \textit{stopwords}.
	Também são usadas outras técnicas, como a eliminação de palavras com a frequência muito alta ou muito baixa.

	% \subsubsection{Lematização} (?)

	\subsubsection{Stemming}

	A fim de reduzir a ambiguidade de palavras, o método de \textit{stemming} é capaz de juntar em uma única forma palavras relacionadas \cite{Miner2012}, como exemplo o verbo \textit{fazer}, que pode se apresentar em diversas formas, como \textit{fazendo}, \textit{fez}, etc. Esse processo pode ser capaz de aumentar a capacidade da representação em distinguir ou identificar documentos.

	\subsubsection{Redução de Dimensionalidade}

	A representação em vetor de palavras pode resultar em vetores esparsos num espaço de alta dimensão, que pode fazer com que algoritmos sofram do problema de \textit{Maldição de Dimensionalidade} (footnote haykin).
	Para amenização desse problema, são usados métodos de \textit{redução de dimensionalidade}.
	A técnica mais comum de \textit{redução de dimensionalidade} é chamada \textit{Análise dos Componentes Principais} (\textit{Principal Component Analysis - PCA}) \cite{Murphy2012}.
	Esta técnica tem o objetivo de encontrar uma representação compacta através da descoberta de $k$ vetores n-dimensionais ortogonais aos dados ($\vec{v}$), em que $k \leq m$. Os vetores são encontrados a partir da minimização da projeção dos dados em $\vec{v}$.
	Depois de encontrados os vetores $\vec{v}$, é feita a projeção dos dados nesses vetores, resultando em uma representação num espaço mais compacto \cite{Kamber2011}.
	É possível aplicar o algoritmo \textit{PCA}, no vetor de palavras, diminuindo a dimensionalidade e esparsidade, superando o problema de \textit{Maldição de Dimensionalidade}.


\chapter{Sistemas de Recomendação por Conteúdo e Aprendizado de Máquina}

%  - instanciação do framework de text mining aqui
\textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}

\textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}

\textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}

\textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}

\textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}

\textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}

\textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}

\chapter{Proposta}

% Um parágrafo inicial. \textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}



\textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}

\section{Apresentação do corpus IG}

% \textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}

O corpus do IG é composto por um conjunto de notícias $\{ n_1, n_2, \dots, n_m \}$ em que cada notícia $n_i$ é representado pela tupla $(t, st, b, c_i)$, onde $t$ é o título, $st$ o subtítulo, $b$ o corpo da notícia e $c_i$ um elemento do conjunto de canais $\{ gente , ultimosegundo , delas , \\economia , esporte , saude , igay , deles , tecnologia , receitas , igirl , jovem , arena , luxo \}$, em que cada canal representa um assunto ou tópico de notícias.

% \textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}

O número total de notícias é $m = xxx$, ...

\subsection{Pré processamento do corpus IG}

\textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}

\textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}

\section{Estudos iniciais de biclustering no corpus IG}

\textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}

\textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}

\textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}

\textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}

\section{Próximos passos - cronograma}

\textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}

\textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}

\textcolor{red}{Texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto texto.}
	
% ********** REFERÊNCIAS **********

%\bibliography{abnt-options,abnt-10520-2001,abnt-10520-2002,abnt-6023-2000,normas,abnt-test,abntex-doc,dissertacao}

\bibliography{refs}					% o nome do arquivo .bib com as referências

%***********************************
%***** Anexos e Apêndices *********
%***********************************


\end{document}
